{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lr\n",
    "import librosa.display\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_plot(audio_file):\n",
    "    audio, Fs = lr.load(audio_file) #Fs is the sampling rate\n",
    "\n",
    "    #print(audio.size/Fs) #gives the time duration of the audio signal\n",
    "    #print(Fs)\n",
    "\n",
    "    Ts = 1.0/Fs #Time step of a single sample\n",
    "    t = numpy.arange(0, len(audio)/Fs, Ts) #time vector\n",
    "\n",
    "    N = len(audio) #total number of samples\n",
    "    #k = numpy.arange(N)\n",
    "    #T = N/Fs #time duration of the audio signal\n",
    "    #f = k/T #since I need total 'k' samples in the time duration of the audio\n",
    "    f = numpy.fft.fftfreq(N, d=Ts)\n",
    "\n",
    "    fft_audio = numpy.fft.fft(audio)/N\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12, 4))\n",
    "    ax[0].plot(t, audio)\n",
    "    ax[0].set_xlabel('Time')\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    \n",
    "    ax[1].plot(f/1000, abs(fft_audio)) \n",
    "    ax[1].set_xlabel('Freq (KHz)')\n",
    "    ax[1].set_ylabel('|Y(freq)|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 9\n",
    "n_aud_files = 67\n",
    "\n",
    "files = numpy.empty([n_class, n_aud_files], dtype=object)\n",
    "\n",
    "data_folder = glob.glob(\"../Read_Up/*\")\n",
    "#print(data_folder)\n",
    "\n",
    "for (i, session) in zip(range(n_class), data_folder):\n",
    "    for (j, aud_file) in zip(range(n_aud_files), glob.glob(\"%s/*\"%session)):\n",
    "        files[i][j] = aud_file\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_plot('../Read_Up/IDR1/1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(866, 13)\n",
      "(866, 26)\n",
      "(866, 13)\n",
      "[  9.0981951  263.80518191 194.81658139 328.84020909 200.83098183\n",
      " 471.91991385 155.96378967 410.56157023 187.31141606 272.79651232\n",
      " 133.62223024 136.64788234  83.83187247]\n"
     ]
    }
   ],
   "source": [
    "audio, Fs = lr.load('../Read_Up/IDR1/06.wav') #fs = 22050\n",
    "mfcc_feat = mfcc(audio, Fs, winlen=0.023)\n",
    "d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "fbank_feat = logfbank(audio, Fs, winlen=0.023)\n",
    "\n",
    "#551=Fs*25ms\n",
    "\n",
    "print(mfcc_feat.shape)\n",
    "print(fbank_feat.shape)\n",
    "print(d_mfcc_feat.shape)\n",
    "\n",
    "print(np.var(mfcc_feat, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00797312]\n"
     ]
    }
   ],
   "source": [
    "audio, Fs = lr.load('../Read_Up/IDR1/06.wav') #fs = 22050\n",
    "chroma = lr.feature.chroma_stft(y=audio, sr=Fs, n_fft=512)\n",
    "mfcc = lr.feature.mfcc(y=audio, sr=Fs, n_mfcc=13, n_fft=512)\n",
    "melspectro = lr.feature.melspectrogram(y=audio, sr=Fs, n_fft=512, n_mels=40)\n",
    "rmse_coeff = lr.feature.rmse(y=audio, frame_length=512)\n",
    "\n",
    "print(np.mean(rmse_coeff.T, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_files = []\n",
    "for i in range(n_class):\n",
    "    for j in range(n_aud_files):\n",
    "        aud, Fs = lr.load(files[i][j])\n",
    "        audio_files.append([aud, Fs, i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(audio_files):\n",
    "    output = []\n",
    "    for i in audio_files:\n",
    "        aud = i[0]\n",
    "        rate = i[1]\n",
    "        label = i[2]\n",
    "        mfcc_array = mfcc(aud, rate, winlen=0.023)\n",
    "        n = mfcc_array.shape[0]\n",
    "        m = mfcc_array.shape[1]\n",
    "        final_mfcc = []\n",
    "        for j in range(m):\n",
    "            tot = 0\n",
    "            for i in range(n):\n",
    "                tot += mfcc_array[i][j]\n",
    "            final_mfcc.append((tot*1.0)/n)\n",
    "        final_mfcc.append(label)\n",
    "        output.append(final_mfcc)\n",
    "    return output\n",
    "\n",
    "\n",
    "inp = get_features(audio_files)\n",
    "train, test = train_test_split(inp, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = numpy.array(train)\n",
    "test = numpy.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = numpy.delete(train,13,1)\n",
    "y_train = train[:, 13]\n",
    "\n",
    "x_test = numpy.delete(test,13,1)\n",
    "y_test = test[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= RandomForestClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
